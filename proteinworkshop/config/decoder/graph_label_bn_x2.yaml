graph_label:
  _target_: "proteinworkshop.models.decoders.mlp_decoder.MLPDecoder"
  hidden_dim: [512, 512]
  dropout: 0.0 # dropout rate
  activations: [ "leaky_relu", "leaky_relu", "none"]
  skip: False # Or sum/False
  out_dim: ${dataset.num_classes}
  input: "graph_embedding"
  batch_norm: True
  batch_norm_output: False
